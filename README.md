# image-fragment-grouping

This code trains and evaluates a model that groups unordered image fragments back to their original source images. Each source image has a square format with 64 x 64 pixels and 3 color channels. For data generation, a single sample is created from 10 images randomly selected from the provided ImageNet64 dataset. Each image is fragmented into 4x4 non-overlapping fragments and the resulting collection of image fragments are shuffled. This results in an unordered collection of 160 image fragments per sample which have be grouped back to their source images.

The model is trained so that the image fragment features generated by the model can be used for mapping back to the original source image. Specifically, the model is trained so that image fragments from the same source image produce ``similar" features, while image fragments from different source images produce ``distinct" features. To facilitate this training, a contrastive learning approach is used.

## Requirements

- Python 3.10+ 
- pip (Python package manager)

## Installation

### 1. Clone the repository

```bash
git clone https://github.com/qpcode/image-fragment-grouping.git
cd image-fragment-grouping
```

### 2. Create a virtual environment

```bash
# On macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

## Usage

```

### Command Line Usage (to be run from the src folder)

```bash
# A training example
python train.py --path-to-data-folder PATH_TO_IMAGENET64_DATA --batch-size 128 --feature-dimension 128 --model-type linear

# An evaluate example
python evaluate.py --eval-file-path PATH_TO_IMAGENET64_DATA/dev_data/dev_data_batch_1 --feature-dimension 128 --model-type linear --epoch-num 1
```

## Project Structure

```
image-fragment-grouping/
│
├── src/    # Source code
│       ├── cluster_metrics.py
│       ├── data_loader.py
│       └── datasets.py
│       └── evaluate.py
│       └── image_fragmentation_models.py
│       └── loss.py
│       └── train.py
│       └── eval_visualization.ipynb
│       └── train_sweep.sh
├── data/                   # Data files (the Imagnet64 dataset has to be placed here)
├── requirements.txt        # Production dependencies
├── README.md              # This file
```
